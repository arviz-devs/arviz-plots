{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06954271-7cc3-4651-9d1b-27352bbd0372",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "(compose_own_plot)=\n",
    "# Create your own figure with `PlotCollection`\n",
    "\n",
    "This tutorial covers how to use `PlotCollection` to simplify the creation of bespoke visualizations. We will cover how to create `PlotCollection` classes directly and two common strategies to fill your {term}`figure` using your `PlotCollection` instance.\n",
    "\n",
    "## `PlotCollection` design overview\n",
    "The main goal of the `PlotCollection` class is to allow you to write plotting functions that are purely plotting functions. No need to worry about {term}`faceting` or {term}`aesthetic mappings`.\n",
    "\n",
    "You can then generate a `PlotCollection` with the {term}`faceting` strategy and {term}`aesthetic mappings` you want and apply those functions through {meth}`~arviz_plots.PlotCollection.map`. `.map` will subset your data and pass each subset along with its corresponding {term}`plot` and {term}`aesthetics` to your function as many times as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200cffaf-fc4d-414c-906c-e1295f247a53",
   "metadata": {},
   "source": [
    "## Tutorial data overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d62759e5-b25d-45fa-8907-fc40283850c6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import arviz_stats as azs\n",
    "import arviz_plots as azp\n",
    "\n",
    "azp.style.use(\"arviz-variat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d163d20-7725-4b21-8f41-448f8ba06691",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [intercept, beta, sigma]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94287d4616c4025bc3c472a9fce1c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 4 seconds.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 59\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Generate a grid of points to evaluate on ---------------------------------------------\u001b[39;00m\n\u001b[1;32m     55\u001b[0m n_interp_points \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m     56\u001b[0m xi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate(\n\u001b[1;32m     57\u001b[0m     [\n\u001b[1;32m     58\u001b[0m         np\u001b[38;5;241m.\u001b[39mlinspace(group[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mmin(), group[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mmax(), n_interp_points)\n\u001b[0;32m---> 59\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgroup\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     ]\n\u001b[1;32m     61\u001b[0m )\n\u001b[1;32m     62\u001b[0m g \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mconcatenate([[i] \u001b[38;5;241m*\u001b[39m n_interp_points \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_groups)])\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     63\u001b[0m predict_at \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: xi, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m\"\u001b[39m: g, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: np\u001b[38;5;241m.\u001b[39mzeros_like(xi)}\n",
      "File \u001b[0;32m~/anaconda3/envs/arviz_1/lib/python3.12/site-packages/pandas/core/frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9186\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/arviz_1/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m~/anaconda3/envs/arviz_1/lib/python3.12/site-packages/pandas/core/groupby/grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'group'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import xarray as xr\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "# generate data ------------------------------------------------------------------------\n",
    "n_groups = 4\n",
    "group_size = [2, 4, 6, 8]\n",
    "\n",
    "# Group-specific parameters\n",
    "slopes = rng.normal(1, 0.2, size=n_groups)\n",
    "intercepts = rng.normal(0, 1, size=n_groups)\n",
    "\n",
    "# Generate data\n",
    "data = []\n",
    "for i in range(n_groups):\n",
    "    n = group_size[i]\n",
    "    x_vals = np.sort(rng.uniform(0, 20, size=n))\n",
    "    noise = rng.normal(0, 1, size=n)\n",
    "    y_vals = slopes[i] * x_vals + intercepts[i] + noise\n",
    "    group_labels = np.full(n, i)\n",
    "    data.append(pd.DataFrame({\"x\": x_vals, \"y\": y_vals, \"group\": group_labels}))\n",
    "\n",
    "# Combine all groups into a single DataFrame\n",
    "df = pd.concat(data, ignore_index=True)\n",
    "df[\"group\"] = df[\"group\"].astype(\"category\")\n",
    "\n",
    "# Build a PyMC model -------------------------------------------------------------------\n",
    "prior_mean = 0\n",
    "prior_std = 1\n",
    "\n",
    "x_data = df.x.values\n",
    "y_data = df.y.values\n",
    "\n",
    "coords = {\"groups\": df[\"group\"].cat.categories, \"obs_id\": df.index}\n",
    "\n",
    "with pm.Model(coords=coords) as model:\n",
    "    x = pm.Data(\"x\", x_data, dims=\"obs_id\")\n",
    "    y = pm.Data(\"y\", y_data, dims=\"obs_id\")\n",
    "    group = pm.Data(\"group\", df[\"group\"].cat.codes.values, dims=\"obs_id\")\n",
    "    # priors\n",
    "    intercept = pm.Normal(\"intercept\", mu=0, sigma=10, dims=[\"groups\"])\n",
    "    beta = pm.Normal(\"beta\", mu=prior_mean, sigma=prior_std, dims=[\"groups\"])\n",
    "    sigma = pm.HalfNormal(\"sigma\", sigma=5)\n",
    "    # likelihood\n",
    "    mu = pm.Deterministic(\"mu\", intercept[group] + beta[group] * x, dims=\"obs_id\")\n",
    "    pm.Normal(\"obs\", mu=mu, sigma=sigma, observed=y, dims=\"obs_id\")\n",
    "    # sample\n",
    "    idata = pm.sample()\n",
    "\n",
    "# Generate a grid of points to evaluate on ---------------------------------------------\n",
    "n_interp_points = 20\n",
    "xi = np.concatenate(\n",
    "    [\n",
    "        np.linspace(group[1].x.min(), group[1].x.max(), n_interp_points)\n",
    "        for group in df.groupby(\"group\")\n",
    "    ]\n",
    ")\n",
    "g = np.concatenate([[i] * n_interp_points for i in range(n_groups)]).astype(int)\n",
    "predict_at = {\"x\": xi, \"group\": g, \"y\": np.zeros_like(xi)}\n",
    "\n",
    "# Posterior prediction on the grid of points -------------------------------------------\n",
    "coords = {\"groups\": predict_at[\"group\"], \"obs_id\": np.arange(len(xi))}\n",
    "\n",
    "with model:\n",
    "    pm.set_data(predict_at, coords=coords)\n",
    "    idata.extend(\n",
    "        pm.sample_posterior_predictive(\n",
    "            idata,\n",
    "            var_names=[\"mu\"],\n",
    "            random_seed=rng,\n",
    "            progressbar=False,\n",
    "            predictions=True,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89d7118-640c-4dbd-aa0c-5f743ab78b43",
   "metadata": {},
   "source": [
    "Our data for the tutorial is a regression model with unpooled slope and intercept; each `group` has their own regression coefficients. Moreover, the number of observations within each group is different. Therefore, we can't have `group` as a dimension of our data. We could have, and actually had, a `group` dimension in some of the model parameters. For the data we add that information as coordinate values of the `obs_id` dimension which represents individual observations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5ebfb1-0f79-4c8e-87bb-dd3d460825a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xr.merge((idata.constant_data, idata.observed_data)).set_coords(\"group\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b9db63-0005-4502-84ac-57c541a3db55",
   "metadata": {},
   "source": [
    "We also define a linspace over the `x` values on which to predict for a dense grid. Thus we also have a `pred_data` Dataset, which holds the input grid over which predicitons were made, and a `predictions` Dataset, which holds these predictions. In each of these Datasets we were careful to use the same `group` coordinate. Note, however, that although the set of labels is the same as `data`, the values are now different, and correspond to the prediction data!\n",
    "\n",
    ":::{note}\n",
    "For the predictions, we use different linspaces for each group but they all have the same number of elements, so it would be possible to use {func}`~xarray_einstats.einops.rearrange` to reshape the data into `(group, obs_id)` shape. As that is not necessary to use the data with `PlotCollection` we will stick to using the extra coordinate with the group factors.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8bd5fd-7d78-4543-bbcc-0128a358e2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_data = idata.predictions_constant_data.set_coords(\"group\")\n",
    "pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ed842-235f-46ed-88e8-a0b6f464bd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = idata.predictions.assign_coords(group=pred_data[\"group\"])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c3a063-82c7-45f3-b199-7cfae9d06a80",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Initializing a `PlotCollection`\n",
    "\n",
    "The two main ways to initialize a `PlotCollection` are {meth}`~arviz_plots.PlotCollection.grid` and {meth}`~arviz_plots.PlotCollection.wrap`. Which method you choose defines the faceting strategy. The specific faceting depends on the `cols`, `rows` and `col_wrap` arguments, and {term}`aesthetic mappings` are defined in the same way independently of the method.\n",
    "\n",
    "In this section, we will use the two approaches above interchangeably to show that they both produce the same results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db2ecb7-8a13-4038-b97d-a3e3ab97a42c",
   "metadata": {},
   "source": [
    "### Defining the faceting\n",
    "We can use {meth}`~arviz_plots.PlotCollection.grid` to generate columns of {term}`plots` per group. If we map nothing to the rows we'll get 4 plots total, one per group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecb664c-9e30-474d-b601-1590b1aa7456",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = azp.PlotCollection.grid(\n",
    "    data[[\"obs\"]],\n",
    "    cols=[\"group\"],\n",
    "    figure_kwargs={\"sharex\": True, \"sharey\": True, \"figsize\": (5, 2)}\n",
    ")\n",
    "pc.map(azp.visuals.scatter_xy, x=data[\"x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a1f29c-a111-4afa-ad23-48e26749edf6",
   "metadata": {},
   "source": [
    "We can also use {meth}`~arviz_plots.PlotCollection.wrap` to generate a grid with a fixed number of columns and as many rows as needed.\n",
    "If we set `col_wrap` to 3, we'll get 2 rows. The first one will have 3 plots and the 2nd will have only one plot so we get to our total of 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4ed11c-56ab-4c1e-a9cd-d769e36c946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = azp.PlotCollection.wrap(\n",
    "    data[[\"obs\"]],\n",
    "    cols=[\"group\"],\n",
    "    col_wrap=3,\n",
    "    figure_kwargs={\"sharex\": True, \"sharey\": True, \"figsize\": (4, 3)}\n",
    ")\n",
    "pc.map(azp.visuals.scatter_xy, x=data[\"x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66c4c1f-eb1d-4bd9-aead-43446455df57",
   "metadata": {},
   "source": [
    "We can also use `.grid` to generate one plot per combination of `group` and `chain` -> 16 total. In this case we'll use the average regression lines in `prediction`. We'll reduce only the \"draw\" dimension when averaging so our data still has the \"chain\" dimension for us to facet along."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be38669b-d900-4efd-9b1c-a4c73455ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = azp.PlotCollection.grid(\n",
    "    predictions.mean(\"draw\"),\n",
    "    cols=[\"group\"],\n",
    "    rows=[\"chain\"],\n",
    "    figure_kwargs={\"sharex\": True, \"sharey\": True, \"figsize\": (8, 4)}\n",
    ")\n",
    "pc.map(azp.visuals.line_xy, x=pred_data[\"x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ac5e75-44e9-4f16-b355-9a7f0e6d39bd",
   "metadata": {},
   "source": [
    "### Defining the aesthetic mappings\n",
    "Aesthetic mappings are always defined via the `aes` keyword argument of the `PlotCollection` initialization methods. It can be used on its own:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92172289-c6a0-4633-a37a-33ad30dcc3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = azp.PlotCollection.grid(\n",
    "    data[[\"obs\"]],\n",
    "    aes={\"color\": [\"group\"]},\n",
    "    figure_kwargs={\"figsize\": (3, 2)}\n",
    ")\n",
    "pc.map(azp.visuals.scatter_xy, x=data[\"x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e383e517-ee34-4003-a3da-509b101de1d4",
   "metadata": {},
   "source": [
    "or combined with faceting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905a0819-cee4-4c59-9611-cf2068e25386",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = azp.PlotCollection.grid(\n",
    "    data[[\"obs\"]],\n",
    "    cols=[\"group\"],\n",
    "    aes={\"color\": [\"group\"]},\n",
    "    figure_kwargs={\"sharex\": True, \"sharey\": True, \"figsize\": (5, 2)}\n",
    ")\n",
    "pc.map(azp.visuals.scatter_xy, x=data[\"x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd24d6b5-e60f-4bce-a569-da0ae39360c1",
   "metadata": {},
   "source": [
    "Recall that faceting and aesthetics are independent mappings, allowing for highly flexible customization. For details on how to use those arguments, see `TODO: add reference`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de757e27-38ef-4a08-b63e-1fdc0d703660",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_chain = azp.PlotCollection.grid(\n",
    "    predictions.mean(\"draw\"),\n",
    "    cols=[\"group\"],\n",
    "    rows=[\"chain\"],\n",
    "    aes={\"color\": [\"group\"]},\n",
    "    figure_kwargs={\"sharex\": True, \"sharey\": True, \"figsize\": (8, 4)}\n",
    ")\n",
    "pc_chain.map(azp.visuals.line_xy, x=pred_data[\"x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cbe4dd-e768-4052-b1a5-3e8b329744ff",
   "metadata": {},
   "source": [
    "## Writing your plotting function(s)\n",
    "We want a plotting function that can be used through `PlotCollection.map`. As we have mentioned, `PlotCollection` subsets and ensures alignment between the data subsets, the {term}`plot` and the {term}`aesthetics`. Consequently, our function will need to accept at least these 3 elements. The expected call signature of `.map` compatible functions is `fn(da, target, ..., **kwargs)`.\n",
    "\n",
    "* `da` is a {class}`~xarray.DataArray` a subset of the input data\n",
    "* `target` is the plotting backend object representing the {term}`plot` corresponding to this subset\n",
    "* `**kwargs` will contain the key-value pairs for all {term}`aesthetic mappings` corresponding to this subset\n",
    "\n",
    "Other than that, it can be a single function that adds multiple {term}`visual elements <visuals>` at once or multiple visual specific functions or a combination of both. `arviz_plots` provides some visual specific functions in `arviz_plots.visuals`, but most bespoke visualizations will probably need something not available there.\n",
    "\n",
    "As a first step to facilitate quick iteration, it can be better to use a monolithic function. Then as the visualization solidifies and more fine grained control is required, it becomes necessary to switch to visual-specific functions.\n",
    "In this tutorial we will showcase the two approaches. To do so we will use a common regression plot with 3 elements: observation xy scatter, posterior mean regression line, and hdi band over the predicted distributions. and showcase the two approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434ffaee-1f26-4fdc-85e5-0ba637caf1d8",
   "metadata": {},
   "source": [
    "### Option 0: the for-loop workflow\n",
    "In the previous ArviZ version, any custom plot that required faceting or aesthetic mappings meant you as a user had to manually take care of that. Legends also needed to be handled mostly manually by using the `label` argument or calling the legend generating function with custom graphical elements and labels.\n",
    "\n",
    "Here is an example of overlaying all 4 groups on the same plot using a different color for each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f0e2f3-55b1-436e-8187-e7fbc82738a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "unique_groups = np.unique(data[\"group\"])\n",
    "colors = [f\"C{i}\" for i in range(len(unique_groups))]\n",
    "\n",
    "fig, axes = plt.subplots(1, 1)  # if faceting subplots(1, 4) instead for example\n",
    "for i, group in enumerate(unique_groups):\n",
    "    # get subsets and corresponding plots+aesthetics\n",
    "    data_subset = data.query(obs_id=f\"group == {group}\")\n",
    "    pred_data_subset = pred_data.query(obs_id=f\"group == {group}\")\n",
    "    predictions_subset = predictions.query(obs_id=f\"group == {group}\")\n",
    "    ax = axes  # if faceting axes[i] instead for example\n",
    "    color = colors[i]\n",
    "    # start plotting\n",
    "    mean = predictions_subset[\"mu\"].mean((\"chain\", \"draw\"))\n",
    "    ax.plot(data_subset[\"x\"], data_subset[\"obs\"], \"o\", color=color, label=f\"Group {i}\")\n",
    "    ax.plot(pred_data_subset[\"x\"], mean, color=color)\n",
    "    # az.plot_hdi(pred_data_subset[\"x\"], predictions_subset[\"mu\"], color=color, ax=ax)\n",
    "    # plot_hdi has no equivalent in arviz-plots\n",
    "    # so we replicate its behaviour in this specific context\n",
    "    hdi = predictions_subset[\"mu\"].azstats.hdi()\n",
    "    ax.fill_between(\n",
    "        pred_data_subset[\"x\"],\n",
    "        hdi.sel(ci_bound=\"lower\"),\n",
    "        hdi.sel(ci_bound=\"upper\"),\n",
    "        color=color,\n",
    "        alpha=0.2\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67de356-2305-456b-9917-5bd647fb22dd",
   "metadata": {},
   "source": [
    "If using a pattern similar to this one, you should be able to copy anything after subsetting `data` and `axes` into a monolithic plotting function and use it through `PlotCollection` to easily change faceting and aesthetics without needing to modify the plotting code at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0215d038-8c67-4a55-ab6c-3501ad0599a1",
   "metadata": {},
   "source": [
    "### Option 1: monolithic function\n",
    "The monolithic function approach is best explained via example. In the next cell, we write a function that replaces \"the for-loop workflow\" illustrated above with a single call to `.map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06eaad1c-efae-4072-b770-fccb239f7cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_band_dots(da, target, x_pred, x, y, **kwargs):\n",
    "    \"\"\"Add mean line, hdi band and observation xy scatter to a matplotlib plot.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    da : DataArray\n",
    "        Predicted samples for the regression line mean and HDI band.\n",
    "    target : matplotlib.axes.Axes\n",
    "    x_pred : DataArray\n",
    "        Independent variable used to generate the predicted samples\n",
    "    x : DataArray\n",
    "        Observed independent data\n",
    "    y : DataArray\n",
    "        Observed dependent data, what we were aiming to model\n",
    "    **kwargs\n",
    "        Passed downstream to matplotlib plotting functions\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    hdi = da.azstats.hdi()\n",
    "    target.fill_between(\n",
    "        x_pred,\n",
    "        hdi.sel(ci_bound=\"lower\"),\n",
    "        hdi.sel(ci_bound=\"upper\"),\n",
    "        alpha=0.3,\n",
    "        **kwargs\n",
    "    )\n",
    "    target.plot(x_pred, da.mean(dim=[\"chain\", \"draw\"]), **kwargs)\n",
    "    target.plot(x, y, \"o\", **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e03e851-6fbf-42e5-b497-56a1a86c305d",
   "metadata": {},
   "source": [
    "In this case we will use `predictions[[\"mu\"]]` to initialize the `PlotCollection` and then the constant data for the predictions and the observations will be passed as keyword arguments.\n",
    "The first argument `da` is a subset of the data uset to initialize the `PlotCollection`.\n",
    "Consequently, we use it to plot the HDI band and the regression line.\n",
    "\n",
    "The second argument, `target`, is whichever class of the plotting backend being used represents a {term}`plot`. With matplotlib it will be {class}`matplotlib.axes.Axes`, for bokeh it will be a {class}`bokeh.plotting.figure`.\n",
    "\n",
    "As indicated in its docstring, {meth}`~arviz_plots.PlotCollection.map` checks the provided kwargs before passing them to the function being called,\n",
    "and subsets xarray objects if possible. That means that we can use `DataArray` and `Dataset` objects as kwargs in `.map` which will be passed to the function being called as `DataArray`s. The only restriction is on `Dataset`s which if used need to have the same variables (or a subset) of those in the `data` argument. We will pass the observed data and `pred_data[\"x\"]` through these keyword arguments.\n",
    "\n",
    "As we mentioned initially we use `**kwargs` to catch the aesthetic kwargs that will be injected by `PlotCollection` and then forward those to the plotting functions themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1f42fa-3ce7-4ae9-9045-73e47497510d",
   "metadata": {},
   "source": [
    "We have said that its main advantages are quick iteration and migration from \"the for-loop workflow\". It is only fair to cover the other side of the coin. Its main disadvantage is that everything is done from a single function, so all the different {term}`visuals` must use the same {term}`aesthetic mappings`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0721532d-14e1-48ce-9da5-5f8547bd9363",
   "metadata": {},
   "source": [
    "Let's see it in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5226549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ae767d-f77d-4d42-b447-8fcdab1d71e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = azp.PlotCollection.grid(\n",
    "    predictions,\n",
    "    aes={\"color\": [\"group\"]},\n",
    "    figure_kwargs={\"figsize\": (3, 2)}\n",
    ")\n",
    "pc.map(line_band_dots, x_pred=pred_data[\"x\"], x=data[\"x\"], y=data[\"obs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1421e0f3-0b9e-4676-a697-bb0c4d8d6223",
   "metadata": {},
   "source": [
    "We can radically change the layout of the generated figure without needing to update our plotting functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47ec104-4c73-40ac-80ae-7a8206a19aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = azp.PlotCollection.wrap(\n",
    "    predictions,\n",
    "    cols=[\"group\"],\n",
    "    col_wrap=3,\n",
    "    figure_kwargs={\"figsize\": (4, 3)}\n",
    ")\n",
    "pc.map(line_band_dots, x_pred=pred_data[\"x\"], x=data[\"x\"], y=data[\"obs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcd22ed-03f0-49de-91b2-b1b30e79b252",
   "metadata": {},
   "source": [
    "In the plot we have generated, notice that we are not setting color anywhere. In this case, the colors are being set using the defaults of our chosen backend (matplotlib in this case)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c390ae8-d247-4036-96cd-4373cc7ef67a",
   "metadata": {},
   "source": [
    "### Option 2: specific functions for each visual element\n",
    "\n",
    "Another option, which is what {ref}`batteries-included plots <plots_intro>` do, is writing multiple functions, one for each conceptually different thing to add/do to the plot. To reproduce the example above we'd then need 3 functions: one for the scatter, one for the line and one for the band.\n",
    "\n",
    "This approach can be harder to get started on, especially if coming from an existing plot as mentioned in the previous section, but it is much more powerful. The main advantage is that we can use different aesthetics in each of the different elements. A secondary advantage is it also allows storing the plotting backend classes representing the different visuals into the `.viz` attribute and to then modify some of them afterwards if desired as shown in {ref}`use_plotcollection`.\n",
    "\n",
    "Moreover, as this is what batteries-included plots do, there are several such functions ready to use in `arviz_plots.visuals`. That being said, the goal of the library is not to provide a comprehensive catalog of these functions, only to expose the ones available that are used somewhere else within the library.\n",
    "\n",
    "In this particular case, we can use {func}`arviz_plots.visuals.line_xy` and {func}`arviz_plots.visuals.scatter_xy` so we'll only add a visual specific function for the HDI band.\n",
    "\n",
    "The `line_xy` function takes the data and plots a line from it, so we'll need to precompute the mean and use that as input. To keep things consistent, we'll do the same for the HDI. This is yet another difference with the case above, but using this pattern will prevent any recomputation every time you want to generate a plot with this data. You'll only need to recompute if you wanted to, for example, change how the data is reduced. It is also worth noting that we could also do this with the monolithic function, we'd only need to add some extra kwargs to take the precomputed quantities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91220834-9eaa-403f-92a9-1efcaf9b4e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hdi_band(da, target, x, **kwargs):\n",
    "    return target.fill_between(x, da.sel(ci_bound=\"lower\"), da.sel(ci_bound=\"upper\"), **kwargs)\n",
    "\n",
    "hdi_ds = predictions.azstats.hdi()\n",
    "mean_ds = predictions.mean([\"chain\", \"draw\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ac023-ef6e-4155-8ecc-85c236e2f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = azp.PlotCollection.grid(\n",
    "    predictions,\n",
    "    aes={\"color\": [\"group\"]},\n",
    "    figure_kwargs={\"figsize\": (3, 2)}\n",
    ")\n",
    "pc.map(hdi_band, data=hdi_ds, x=pred_data[\"x\"], alpha=0.3)\n",
    "pc.map(azp.visuals.line_xy, data=mean_ds, x=pred_data[\"x\"])\n",
    "pc.map(azp.visuals.scatter_xy, y=data[\"obs\"], x=data[\"x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef1f3c0-40a4-4abf-98e9-122d92700d66",
   "metadata": {},
   "source": [
    "we can also reproduce the other plot we have generated from the monolithic function. We initialize the `PlotCollection` class in the same way,\n",
    "then call the visual specific functions like we did in the previous cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f7433f-63f3-4ef6-8400-3e785447012f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc = azp.PlotCollection.wrap(\n",
    "    predictions,\n",
    "    cols=[\"group\"],\n",
    "    col_wrap=3,\n",
    "    figure_kwargs={\"figsize\": (4, 3)}\n",
    ")\n",
    "pc.map(hdi_band, data=hdi_ds, x=pred_data[\"x\"], alpha=0.3)\n",
    "pc.map(azp.visuals.line_xy, data=mean_ds, x=pred_data[\"x\"])\n",
    "pc.map(azp.visuals.scatter_xy, y=data[\"obs\"], x=data[\"x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b54c2fd-695b-4b4d-8248-57e5ef82ec04",
   "metadata": {},
   "source": [
    "Recall that faceting and aesthetics are independent mappings, allowing for highly flexible customization. For details on how to use those arguments, see `TODO: add reference`.\n",
    "\n",
    "Moreover, when using visual-specific functions, we can disable aesthetic mappings for some visual elements but leave them active for others. For example, we can keep the group->color mapping and add an extra chain->linestyle mapping, which we'll only use in the line visual element:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05f445b-70b9-4c3a-be6c-b654bebe0afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now need hdi and mean without reducing the \"chain\" dimension\n",
    "# so we redefine hdi_ds and mean_ds\n",
    "hdi_draw_ds = predictions.azstats.hdi(dims=[\"draw\"])\n",
    "mean_draw_ds = predictions.mean(\"draw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8b0962-a4c0-4ccc-9f3d-ceed1d16e061",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_chain = azp.PlotCollection.grid(\n",
    "    predictions,\n",
    "    cols=[\"group\"],\n",
    "    rows=[\"chain\"],\n",
    "    aes={\"color\": [\"group\"], \"linestyle\": [\"chain\"]},\n",
    "    figure_kwargs={\"sharex\": True, \"sharey\": True, \"figsize\": (8, 4)}\n",
    ")\n",
    "pc_chain.map(hdi_band, data=hdi_draw_ds, x=pred_data[\"x\"], ignore_aes={\"linestyle\"}, alpha=0.3)\n",
    "pc_chain.map(azp.visuals.line_xy, data=mean_draw_ds, x=pred_data[\"x\"])\n",
    "pc_chain.map(azp.visuals.scatter_xy, y=data[\"obs\"], x=data[\"x\"], ignore_aes={\"linestyle\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0d9851-5241-4ca6-9888-960de404c9ae",
   "metadata": {},
   "source": [
    "which also works without any facetting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b830916-d1fc-4a64-9100-afac35c27cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from traceback import print_exception\n",
    "\n",
    "pc_chain = azp.PlotCollection.grid(\n",
    "    predictions,\n",
    "    aes={\"color\": [\"group\"], \"linestyle\": [\"chain\"]},\n",
    "    figure_kwargs={\"sharex\": True, \"sharey\": True, \"figsize\": (4, 3)}\n",
    ")\n",
    "try:\n",
    "    pc_chain.map(hdi_band, data=hdi_draw_ds, x=pred_data[\"x\"], ignore_aes={\"linestyle\"}, alpha=0.3)\n",
    "    pc_chain.map(azp.visuals.line_xy, data=mean_draw_ds, x=pred_data[\"x\"])\n",
    "    pc_chain.map(azp.visuals.scatter_xy, y=data[\"obs\"], x=data[\"x\"], ignore_aes={\"linestyle\"})\n",
    "except ValueError as err:\n",
    "    print_exception(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ebb3ce-9eec-443d-b608-2011c6eb9564",
   "metadata": {},
   "source": [
    "The main drawback of the flexibility in faceting, aesthetic mapping and what is allowed as an _aesthetic_ means it is your responsibility to ensure faceting, aesthetic mappings and input data are coherent.\n",
    "\n",
    "In the above cell we use `hdi_draw_ds` whose `chain` dimension hasn't been reduced. We then ignore the linestyle mapping which is the only one we have for `chain` now. That means that we subset over `group` due to the color aesthetic mapping and pass that result to our `hdi_band` function. The function gets an input with dimensions `chain, obs_id, ci_bound` as it can be seen in the cell below, but `hdi_band` expects `data.sel(ci_bound=\"lower\")` to be unidimensional! Not to still have `chain, obs_id` dimensions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f893d784-d25c-4cc3-b8ab-556c5114b8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hdi_draw_ds.query(obs_id=\"group == 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902a4c70-4347-4929-a35b-90725fb2c1d0",
   "metadata": {},
   "source": [
    "If we want a single HDI band per group, we should fix this updating the data to `hdi_ds` where we have already reduced the `chain` dimension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a253a-aaf8-423f-a596-bba2f00dffd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_chain = azp.PlotCollection.grid(\n",
    "    predictions,\n",
    "    aes={\"color\": [\"group\"], \"linestyle\": [\"chain\"]},\n",
    "    figure_kwargs={\"sharex\": True, \"sharey\": True, \"figsize\": (4, 3)}\n",
    ")\n",
    "pc_chain.map(hdi_band, data=hdi_ds, x=pred_data[\"x\"], ignore_aes={\"linestyle\"}, alpha=0.3)\n",
    "pc_chain.map(azp.visuals.line_xy, data=mean_draw_ds, x=pred_data[\"x\"])\n",
    "pc_chain.map(azp.visuals.scatter_xy, y=data[\"obs\"], x=data[\"x\"], ignore_aes={\"linestyle\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0683d25c-1f0a-4dac-9287-b9dab40f111c",
   "metadata": {},
   "source": [
    "If instead we want one band per group and per chain, we have to fix the error by making sure even if we disable the linestyle mapping, there will be something mapped to the `chain` dimension. We will use a mapping on the hatch property to that effect. We will then ignore the hatch mapping for the line and the linestyle mapping for the band:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6430dd5c-0f79-4e3e-b345-bc7572a7cd18",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_chain = azp.PlotCollection.grid(\n",
    "    predictions,\n",
    "    aes={\"color\": [\"group\"], \"linestyle\": [\"chain\"], \"hatch\": [\"chain\"]},\n",
    "    figure_kwargs={\"sharex\": True, \"sharey\": True, \"figsize\": (4, 3)},\n",
    "    hatch=[\"/\", \"+\", \"x\", \"o\"],\n",
    ")\n",
    "pc_chain.map(hdi_band, data=hdi_draw_ds, x=pred_data[\"x\"], ignore_aes={\"linestyle\"}, alpha=0.2)\n",
    "pc_chain.map(azp.visuals.line_xy, data=mean_draw_ds, x=pred_data[\"x\"], ignore_aes={\"hatch\"})\n",
    "pc_chain.map(azp.visuals.scatter_xy, y=data[\"obs\"], x=data[\"x\"], ignore_aes={\"linestyle\", \"hatch\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd569c9-49e1-4025-bfb0-c3ca022bcb83",
   "metadata": {},
   "source": [
    ":::{seealso}\n",
    "* coming soon: In depth explanation of how faceting and aesthetics are handled\n",
    "* {ref}`plots_intro/advanced` has advanced examples using batteries-included plots using complex combinations of faceting and aesthetic mappings.\n",
    "* {ref}`add_new_plot` is a guide for contributors and developers working on batteries-included plots. If you are using `PlotCollection` to generate domain specific plots included in another library it will probably be helpful to you as it covers internal scaffolding to for example know which dimensions to reduce based on `sample_dims` input and existing aesthetic mappings.\n",
    ":::"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arviz_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
